use crate::{env::RedisMode, response::ApiResponse};
use axum::http::StatusCode;
use colored::Colorize;
use compact_str::ToCompactString;
use rustis::{
    client::Client,
    commands::{
        GenericCommands, InfoSection, ServerCommands, SetCondition, SetExpiration, StringCommands,
    },
    resp::BulkString,
};
use serde::{Serialize, de::DeserializeOwned};
use std::{
    future::Future,
    sync::{
        Arc,
        atomic::{AtomicU64, Ordering},
    },
    time::{Duration, Instant},
};

#[derive(Clone, Debug)]
struct DataEntry {
    data: Arc<Vec<u8>>,
    intended_ttl: Duration,
}

#[derive(Clone, Debug)]
struct LockEntry {
    semaphore: Arc<tokio::sync::Semaphore>,
}

struct DataExpiry;

impl moka::Expiry<compact_str::CompactString, DataEntry> for DataExpiry {
    fn expire_after_create(
        &self,
        _key: &compact_str::CompactString,
        value: &DataEntry,
        _created_at: Instant,
    ) -> Option<Duration> {
        Some(value.intended_ttl)
    }
}

pub struct Cache {
    pub client: Arc<Client>,
    use_internal_cache: bool,
    local: moka::future::Cache<compact_str::CompactString, DataEntry>,
    local_locks: moka::future::Cache<compact_str::CompactString, LockEntry>,

    cache_calls: AtomicU64,
    cache_latency_ns_total: AtomicU64,
    cache_latency_ns_max: AtomicU64,
    cache_misses: AtomicU64,
}

impl Cache {
    pub async fn new(env: &crate::env::Env) -> Arc<Self> {
        let start = std::time::Instant::now();

        let client = Arc::new(match &env.redis_mode {
            RedisMode::Redis { redis_url } => Client::connect(redis_url.clone()).await.unwrap(),
            RedisMode::Sentinel {
                cluster_name,
                redis_sentinels,
            } => Client::connect(
                format!(
                    "redis-sentinel://{}/{cluster_name}/0",
                    redis_sentinels.join(",")
                )
                .as_str(),
            )
            .await
            .unwrap(),
        });

        let local = moka::future::Cache::builder()
            .max_capacity(16_384)
            .expire_after(DataExpiry)
            .build();

        let local_locks = moka::future::Cache::builder().max_capacity(4_096).build();

        let instance = Arc::new(Self {
            client,
            use_internal_cache: env.app_use_internal_cache,
            local,
            local_locks,
            cache_calls: AtomicU64::new(0),
            cache_latency_ns_total: AtomicU64::new(0),
            cache_latency_ns_max: AtomicU64::new(0),
            cache_misses: AtomicU64::new(0),
        });

        let version = instance
            .version()
            .await
            .unwrap_or_else(|_| "unknown".into());

        tracing::info!(
            "{} connected {}",
            "cache".bright_yellow(),
            format!(
                "(redis@{}, {}ms, moka_enabled={})",
                version,
                start.elapsed().as_millis(),
                env.app_use_internal_cache
            )
            .bright_black()
        );

        instance
    }

    pub async fn version(&self) -> Result<compact_str::CompactString, rustis::Error> {
        let version: String = self.client.info([InfoSection::Server]).await?;
        let version = version
            .lines()
            .find(|line| line.starts_with("redis_version:"))
            .unwrap_or("redis_version:unknown")
            .split(':')
            .nth(1)
            .unwrap_or("unknown")
            .into();

        Ok(version)
    }

    pub async fn ratelimit(
        &self,
        limit_identifier: impl AsRef<str>,
        limit: u64,
        limit_window: u64,
        client: impl AsRef<str>,
    ) -> Result<(), ApiResponse> {
        let key = compact_str::format_compact!(
            "ratelimit::{}::{}",
            limit_identifier.as_ref(),
            client.as_ref()
        );

        let now = chrono::Utc::now().timestamp();
        let expiry = self.client.expiretime(&key).await.unwrap_or_default();
        let expire_unix: u64 = if expiry > now + 2 {
            expiry as u64
        } else {
            now as u64 + limit_window
        };

        let limit_used = self.client.get::<u64>(&key).await.unwrap_or_default() + 1;
        self.client
            .set_with_options(key, limit_used, None, SetExpiration::Exat(expire_unix))
            .await?;

        if limit_used >= limit {
            return Err(ApiResponse::error(format!(
                "you are ratelimited, retry in {}s",
                expiry - now
            ))
            .with_status(StatusCode::TOO_MANY_REQUESTS));
        }

        Ok(())
    }

    #[tracing::instrument(skip(self))]
    pub async fn lock(
        &self,
        lock_id: impl Into<compact_str::CompactString> + std::fmt::Debug,
        ttl: Option<u64>,
        timeout: Option<u64>,
    ) -> Result<CacheLock, anyhow::Error> {
        let lock_id = lock_id.into();
        let redis_key = compact_str::format_compact!("lock::{}", lock_id);
        let ttl_secs = ttl.unwrap_or(30);
        let deadline = timeout.map(|ms| Instant::now() + Duration::from_secs(ms));

        tracing::debug!("acquiring cache lock");

        let entry = self
            .local_locks
            .entry(lock_id.clone())
            .or_insert_with(async {
                LockEntry {
                    semaphore: Arc::new(tokio::sync::Semaphore::new(1)),
                }
            })
            .await
            .into_value();

        let permit = match deadline {
            Some(dl) => {
                let remaining = dl.saturating_duration_since(Instant::now());
                tokio::time::timeout(remaining, entry.semaphore.acquire_owned())
                    .await
                    .map_err(|_| anyhow::anyhow!("timed out waiting for cache lock `{}`", lock_id))?
                    .map_err(|_| anyhow::anyhow!("semaphore closed for lock `{}`", lock_id))?
            }
            None => entry
                .semaphore
                .acquire_owned()
                .await
                .map_err(|_| anyhow::anyhow!("semaphore closed for lock `{}`", lock_id))?,
        };

        match self
            .try_acquire_redis_lock(&redis_key, ttl_secs, deadline)
            .await?
        {
            true => {
                tracing::debug!("acquired cache lock");
                Ok(CacheLock::new(lock_id, self.client.clone(), permit, ttl))
            }
            false => anyhow::bail!("timed out acquiring redis lock `{}`", lock_id),
        }
    }

    async fn try_acquire_redis_lock(
        &self,
        redis_key: &compact_str::CompactString,
        ttl_secs: u64,
        deadline: Option<Instant>,
    ) -> Result<bool, anyhow::Error> {
        loop {
            let acquired = self
                .client
                .set_with_options(
                    redis_key.as_str(),
                    "1",
                    SetCondition::NX,
                    SetExpiration::Ex(ttl_secs),
                )
                .await
                .unwrap_or(false);

            if acquired {
                return Ok(true);
            }

            if let Some(dl) = deadline {
                let remaining = dl.saturating_duration_since(Instant::now());
                if remaining.is_zero() {
                    return Ok(false);
                }
                tokio::time::sleep(remaining.min(Duration::from_millis(50))).await;
            } else {
                tokio::time::sleep(Duration::from_millis(50)).await;
            }
        }
    }

    #[tracing::instrument(skip(self, fn_compute))]
    pub async fn cached<
        T: Serialize + DeserializeOwned + Send,
        F: FnOnce() -> Fut,
        Fut: Future<Output = Result<T, FutErr>>,
        FutErr: Into<anyhow::Error> + Send + Sync + 'static,
    >(
        &self,
        key: &str,
        ttl: u64,
        fn_compute: F,
    ) -> Result<T, anyhow::Error> {
        let effective_moka_ttl = if self.use_internal_cache {
            Duration::from_secs(ttl)
        } else {
            Duration::from_millis(50)
        };

        let client = self.client.clone();

        self.cache_calls.fetch_add(1, Ordering::Relaxed);
        let start_time = Instant::now();

        let entry = self
            .local
            .try_get_with(key.to_compact_string(), async move {
                tracing::debug!("checking redis cache");
                let cached_value: Option<BulkString> = client
                    .get(key)
                    .await
                    .map_err(|err| {
                        tracing::error!("redis get error: {:?}", err);
                        err
                    })
                    .ok()
                    .flatten();

                if let Some(value) = cached_value {
                    tracing::debug!("found in redis cache");
                    return Ok(DataEntry {
                        data: Arc::new(value.to_vec()),
                        intended_ttl: effective_moka_ttl,
                    });
                }

                self.cache_misses.fetch_add(1, Ordering::Relaxed);

                tracing::debug!("executing compute");
                let result = fn_compute().await.map_err(|e| e.into())?;
                tracing::debug!("executed compute");

                let serialized = rmp_serde::to_vec(&result)?;
                let serialized_arc = Arc::new(serialized);

                let _ = client
                    .set_with_options(key, serialized_arc.as_slice(), None, SetExpiration::Ex(ttl))
                    .await;

                Ok::<_, anyhow::Error>(DataEntry {
                    data: serialized_arc,
                    intended_ttl: effective_moka_ttl,
                })
            })
            .await;

        let elapsed_ns = start_time.elapsed().as_nanos() as u64;
        self.cache_latency_ns_total
            .fetch_add(elapsed_ns, Ordering::Relaxed);

        let _ = self.cache_latency_ns_max.fetch_update(
            Ordering::Relaxed,
            Ordering::Relaxed,
            |current_max| {
                if elapsed_ns > current_max {
                    Some(elapsed_ns)
                } else {
                    Some(current_max)
                }
            },
        );

        match entry {
            Ok(internal_entry) => Ok(rmp_serde::from_slice::<T>(&internal_entry.data)?),
            Err(arc_error) => Err(anyhow::anyhow!("cache computation failed: {:?}", arc_error)),
        }
    }

    pub async fn invalidate(&self, key: &str) -> Result<(), anyhow::Error> {
        self.local.invalidate(key).await;
        self.client.del(key).await?;

        Ok(())
    }

    #[inline]
    pub fn cache_calls(&self) -> u64 {
        self.cache_calls.load(Ordering::Relaxed)
    }

    #[inline]
    pub fn cache_misses(&self) -> u64 {
        self.cache_misses.load(Ordering::Relaxed)
    }

    #[inline]
    pub fn cache_latency_ns_average(&self) -> u64 {
        let calls = self.cache_calls();
        if calls == 0 {
            0
        } else {
            self.cache_latency_ns_total.load(Ordering::Relaxed) / calls
        }
    }
}

pub struct CacheLock {
    lock_id: Option<compact_str::CompactString>,
    redis_client: Arc<Client>,
    permit: Option<tokio::sync::OwnedSemaphorePermit>,
    ttl_guard: Option<tokio::task::JoinHandle<()>>,
}

impl CacheLock {
    fn new(
        lock_id: compact_str::CompactString,
        redis_client: Arc<Client>,
        permit: tokio::sync::OwnedSemaphorePermit,
        ttl: Option<u64>,
    ) -> Self {
        let ttl_guard = ttl.map(|secs| {
            let lock_id = lock_id.clone();
            let redis_client = redis_client.clone();

            tokio::spawn(async move {
                tokio::time::sleep(Duration::from_secs(secs)).await;
                tracing::warn!(%lock_id, "cache lock TTL expired; force-releasing");
                let redis_key = compact_str::format_compact!("lock::{}", lock_id);
                let _ = redis_client.del(&redis_key).await;
            })
        });

        Self {
            lock_id: Some(lock_id),
            redis_client,
            permit: Some(permit),
            ttl_guard,
        }
    }

    #[inline]
    pub fn is_active(&self) -> bool {
        self.lock_id.is_some() && self.ttl_guard.as_ref().is_none_or(|h| !h.is_finished())
    }
}

impl Drop for CacheLock {
    fn drop(&mut self) {
        if let Some(ttl_guard) = self.ttl_guard.take() {
            ttl_guard.abort();
        }

        self.permit.take();

        if let Some(lock_id) = self.lock_id.take() {
            let redis_client = self.redis_client.clone();

            tokio::spawn(async move {
                let redis_key = compact_str::format_compact!("lock::{}", lock_id);
                let _ = redis_client.del(&redis_key).await;
            });
        }
    }
}
